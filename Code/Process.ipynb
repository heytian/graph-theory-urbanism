{"cells":[{"cell_type":"markdown","metadata":{"id":"k6_4BJ2Yzqf8"},"source":["#### Step 1: fclass processing\n","\n","First prepare POIS (points - the code below is a modular script for fclass processing), streets (lines, processed with simplify, planarize, sDNA prepare network, test it out with sDNA integral analysis to check that its ready), POP (polygons)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTS_RsLUzqf9"},"outputs":[],"source":["import arcpy\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tazu6qtgzqf-"},"outputs":[],"source":["#Combine different fields into one fclass within a shp file - for Leisure.geojson converted to point shp\n","\n","shp_path = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250712_Boston_POIS\\original\\Leisure-POINT.shp\"\n","\n","# Define fields to check in order of priority\n","field_priority = [\"amenity\", \"leisure\", \"tourism\"]  # Extend this list as needed\n","output_field = \"fclass\"\n","\n","# --- Add 'fclass' field if it doesn't exist ---\n","existing_fields = [f.name for f in arcpy.ListFields(shp_path)]\n","if output_field not in existing_fields:\n","    arcpy.AddField_management(shp_path, output_field, \"TEXT\")\n","\n","# --- Build the expression ---\n","# Pass all fields into the reclass function\n","expression_fields = \", \".join([f\"!{f}!\" for f in field_priority])\n","expression = f\"reclass({expression_fields})\"\n","\n","# --- Define the code block to check each field in order ---\n","# Accepts variable number of arguments using *args\n","code_block = \"\"\"\n","def reclass(*args):\n","    for val in args:\n","        if val is not None and str(val).strip():\n","            return str(val).lower().replace(' ', '_')\n","    return \"unknown\"\n","\"\"\"\n","\n","# --- Calculate field using expression and code block ---\n","arcpy.CalculateField_management(\n","    in_table=shp_path,\n","    field=output_field,\n","    expression=expression,\n","    expression_type=\"PYTHON3\",\n","    code_block=code_block\n",")\n","\n","print(f\"fclass calculated using priority fields: {field_priority}\")\n","\n","# Optional post-processing: Update unknowns based on 'sport'\n","with arcpy.da.UpdateCursor(shp_path, [\"sport\", \"fclass\"]) as cursor:\n","    for row in cursor:\n","        sport_val, fclass_val = row\n","        if fclass_val == \"unknown\" and sport_val is not None and str(sport_val).strip():\n","            row[1] = \"sports_centre\"\n","            cursor.updateRow(row)\n","\n","print(\"Updated fclass to 'sports_centre' where sport exists and fclass was 'unknown'\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COX381dGzqf-"},"outputs":[],"source":["# modular script for fclass/merge/clip with library config\n","\n","\n","input_folder = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250712_Boston_POIS\\original\"\n","output_folder = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250712_Boston_POIS\\processed\"\n","clip_boundary = r\"Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_boundary_edi_Dissolve\"\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# === CONFIGURATION ===\n","# For each shapefile in input_folder, specify one action:\n","# - \"full\" = add fclass field, calculate it, then clip\n","# - \"clip_only\" = just clip (skip field calc)\n","#   \"merge_only\"  â€“ Do not process or clip, just merge existing file\n","# - \"skip\" = ignore this file completely\n","\n","file_configs = {\n","    \"boston_POIS_work_select.shp\": {\"action\": \"merge_only\"},\n","    \"PLACES_OF_WORSHIP_PT.shp\":     {\"action\": \"full\",\"fixed_fclass\": None,\"source_fields\": [\"TYPE\"]},\n","\n","# example syntax below for various configs:\n","#     \"CHILDCARE_PT.shp\":      {\"action\": \"full\",\"fixed_fclass\": \"childcare\", \"source_fields\": None},\n","#     \"childcare.shp\":     {\"action\": \"full\",\"fixed_fclass\": None,\"source_fields\": [\"CATEGORY\"]},\n","#     \"DCRPOOLS_PT.shp\": {\"action\": \"clip_only\"},\n","#     \"leisure_processed.shp\": {\"action\": \"merge_only\"},  # Already clipped\n","# Add more shapefiles here\n","}\n","\n","# Helper: build CalculateField expression + code block\n","def build_calc_expr_code(fields):\n","    expr = f\"reclass({', '.join(['!' + f + '!' for f in fields])})\"\n","    code_blk = \"\"\"\n","def reclass(*args):\n","    for val in args:\n","        if val is not None and str(val).strip():\n","            return str(val).lower().replace(' ', '_')\n","    return 'unknown'\n","\"\"\"\n","    return expr, code_blk\n","\n","# Collect clipped shapefiles for merging\n","clipped_files = []\n","for fname in os.listdir(input_folder):\n","    if not fname.lower().endswith(\".shp\"):\n","        continue\n","\n","    if fname not in file_configs:\n","        print(f\"Skipping {fname} â€“ not in config\")\n","        continue\n","\n","    config = file_configs[fname]\n","    action = config.get(\"action\", \"skip\")\n","\n","    in_path = os.path.join(input_folder, fname)\n","    base_name = os.path.splitext(fname)[0]\n","    out_path = os.path.join(output_folder, f\"{base_name}_processed.shp\")\n","\n","    if action == \"skip\":\n","        print(f\"Skipping {fname} per config\")\n","        continue\n","\n","    if action == \"merge_only\":\n","        print(f\"Adding {fname} to merge list only (no processing)\")\n","        clipped_files.append(in_path)\n","        continue\n","\n","    if os.path.exists(out_path):\n","        print(f\"Output for {fname} already exists, skipping processing\")\n","        clipped_files.append(out_path)\n","        continue\n","\n","    print(f\"Processing {fname} with action '{action}'\")\n","\n","    if action == \"full\":\n","        # Ensure fclass field exists\n","        existing_fields = [f.name for f in arcpy.ListFields(in_path)]\n","        if \"fclass\" not in existing_fields:\n","            arcpy.AddField_management(in_path, \"fclass\", \"TEXT\")\n","\n","        fixed = config.get(\"fixed_fclass\")\n","        source = config.get(\"source_fields\")\n","\n","        if fixed:\n","            with arcpy.da.UpdateCursor(in_path, [\"fclass\"]) as cursor:\n","                for row in cursor:\n","                    row[0] = fixed\n","                    cursor.updateRow(row)\n","            print(f\"Set fixed fclass '{fixed}' for all features\")\n","\n","        elif source:\n","            expr, code_blk = build_calc_expr_code(source)\n","            arcpy.CalculateField_management(in_path, \"fclass\", expr, \"PYTHON3\", code_blk)\n","            print(f\"Calculated fclass from fields: {source}\")\n","\n","        else:\n","            print(f\"No fclass rule specified, skipping classification\")\n","\n","    if action in (\"full\", \"clip_only\"):\n","        arcpy.Clip_analysis(in_path, clip_boundary, out_path)\n","        clipped_files.append(out_path)\n","        print(f\"Clipped to: {out_path}\")\n","\n","# final merge\n","if clipped_files:\n","    merged_output = os.path.join(output_folder, \"boston_POIS_educivic.shp\")\n","    print(f\"Merging {len(clipped_files)} shapefiles into {merged_output}...\")\n","    arcpy.Merge_management(clipped_files, merged_output)\n","    print(\"Merge complete.\")\n","\n","    # --- Deduplication ---\n","    # Count features before\n","    count_before = int(arcpy.GetCount_management(merged_output)[0])\n","\n","    # Delete exact duplicate points with same fclass\n","    arcpy.DeleteIdentical_management(\n","        in_dataset=merged_output,\n","        fields=[\"Shape\",\"fclass\"],              # Consider adding more fields if needed\n","        xy_tolerance=\"0 Meters\",\n","    )\n","\n","    # Count features after\n","    count_after = int(arcpy.GetCount_management(merged_output)[0])\n","    num_deleted = count_before - count_after\n","\n","    print(f\"Removed {num_deleted} duplicate point(s) from merged shapefile.\")\n","    print(f\"Final output saved at: {merged_output}\")\n","\n","else:\n","    print(\"No shapefiles were processed or found to merge.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Djttrkjzqf_"},"outputs":[],"source":["# clean up attribute fields that are null or empty (useful for geojsons scraped from overpass turbo)\n","\n","import arcpy\n","\n","shp_path = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250712_Boston_POIS\\processed\\boston_POIS_educivic.shp\"\n","\n","# identify fields with null or blank values\n","\n","empty_fields = []\n","\n","# List all fields except OID and geometry\n","fields = [f.name for f in arcpy.ListFields(shp_path) if f.type not in (\"OID\", \"Geometry\")]\n","\n","for field in fields:\n","    has_data = False\n","    with arcpy.da.SearchCursor(shp_path, [field]) as cursor:\n","        for row in cursor:\n","            value = row[0]\n","            if value not in [None, \"\", \" \"]:\n","                has_data = True\n","                break\n","    if not has_data:\n","        empty_fields.append(field)\n","\n","print(\"Fields that are empty across all rows:\")\n","for f in empty_fields:\n","    print(\"   -\", f)\n","\n","# delete those empty rows\n","if empty_fields:\n","    arcpy.DeleteField_management(shp_path, empty_fields)\n","    print(f\"ðŸ§¹ Deleted {len(empty_fields)} empty fields.\")\n","else:\n","    print(\"No empty fields to delete.\")"]},{"cell_type":"markdown","metadata":{"id":"vwFBJxqrzqf_"},"source":["#### Step 2: Spatial joins - road with POIS\n","Spatial join road network with each POIS (cumulatively), within a distance, 400m. Create new column, join count = pois_shop (this is the POIS density). Then spatial join this resulting file with point data files POIS work, POIS educivic, etc. end with 1 file with 4 pois columns\n","Kaunas_streets_good with Kaunas_POIS_work, then the result with Kaunas_POIS_leisure, etc\n","End with 1 file: Kaunas_st_allPOIS, with 4 columns of 4 POIS densities"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"KSadMb2ozqf_","outputId":"e01f25d0-64f0-4a93-c3bb-832c40066986"},"outputs":[{"name":"stdout","output_type":"stream","text":["Joining boston_streets_good.shp with boston_POIS_educivic.shp â†’ boston_streets_good_educivic\n","Saved: Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_streets_good_educivic\n","Calculated density field: p_educivic from Join_Count\n","Deleted intermediate Join_Count field: Join_Count\n","Joining boston_streets_good_educivic with boston_POIS_leisure.shp â†’ boston_streets_good_educivic_leisure\n","Saved: Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_streets_good_educivic_leisure\n","Calculated density field: p_leisure from Join_Count\n","Deleted intermediate Join_Count field: Join_Count\n","Joining boston_streets_good_educivic_leisure with boston_POIS_shopping.shp â†’ boston_streets_good_educivic_leisure_shopping\n","Saved: Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_streets_good_educivic_leisure_shopping\n","Calculated density field: p_shopping from Join_Count\n","Deleted intermediate Join_Count field: Join_Count\n","Joining boston_streets_good_educivic_leisure_shopping with boston_POIS_work.shp â†’ boston_streets_good_educivic_leisure_shopping_work\n","Saved: Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_streets_good_educivic_leisure_shopping_work\n","Calculated density field: p_work from Join_Count\n","Deleted intermediate Join_Count field: Join_Count\n","ðŸ§¹ Final cleanup: Deleted fields â†’ ['TARGET_FID', 'TARGET_FID_1', 'TARGET_FID_12', 'TARGET_FID_12_13', 'Join_Count_1', 'TARGET_FID_12_13_14', 'RDTYPE', 'Shape_Leng', 'Part_Count']\n"]}],"source":["import arcpy\n","import os\n","from itertools import product\n","\n","# define file paths\n","input_folder = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250730_Boston_spatialjoins\\input\"\n","output_folder = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250730_Boston_spatialjoins\\output\"\n","\n","# find files\n","streets = [f for f in os.listdir(input_folder) if f.startswith(\"boston_streets\") and f.endswith(\".shp\")]\n","POIS = [f for f in os.listdir(input_folder) if f.startswith(\"boston_POIS\") and f.endswith(\".shp\")]\n","\n","# Use the first matching streets file\n","base_streets_file = streets[0]\n","current_streets_path = os.path.join(input_folder, base_streets_file)\n","\n","pois_density_fields = []\n","\n","def build_nullable_fieldmap(target_fc, join_fc):\n","    field_mappings = arcpy.FieldMappings()\n","    # Add all fields from the streets (target) layer only\n","    field_mappings.addTable(target_fc)\n","    # Do NOT add any fields from join_fc (POIS)\n","    # Join_Count field will be auto-generated by SpatialJoin\n","    return field_mappings\n","\n","# Track cumulative suffix for naming\n","cumulative_suffix = \"\"\n","\n","# Loop through POI files and join each cumulatively\n","for i, poi_file in enumerate(POIS):\n","    poi_path = os.path.join(input_folder, poi_file)\n","    poi_suffix = poi_file.split(\"boston_POIS_\")[-1].replace(\".shp\", \"\")\n","    cumulative_suffix += f\"_{poi_suffix}\"\n","\n","    gdb_path = r\"Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\"\n","    out_name = f\"{os.path.splitext(base_streets_file)[0]}{cumulative_suffix}\"\n","    out_path = os.path.join(gdb_path, out_name)\n","\n","\n","    print(f\"Joining {os.path.basename(current_streets_path)} with {poi_file} â†’ {out_name}\")\n","\n","    # Prepare field map\n","    field_map = build_nullable_fieldmap(current_streets_path, poi_path)\n","\n","    # Perform spatial join\n","    arcpy.analysis.SpatialJoin(\n","        target_features=current_streets_path,\n","        join_features=poi_path,\n","        out_feature_class=out_path,\n","        join_operation=\"JOIN_ONE_TO_ONE\",\n","        join_type=\"KEEP_ALL\",\n","        field_mapping=field_map,\n","        match_option=\"WITHIN_A_DISTANCE\",\n","        search_radius=\"400 Meters\"\n","    )\n","\n","    print(f\"Saved: {out_path}\")\n","\n","    # Add POIS density field\n","    # Truncate field name to max 10 chars (safe for shapefiles)\n","    density_field = (f\"p_{poi_suffix.lower()}\")[:10]\n","    # Add field with truncated name, but human-readable alias\n","    arcpy.AddField_management(out_path, density_field, \"DOUBLE\", field_alias=f\"POIS_{poi_suffix}\")\n","\n","    pois_density_fields.append(density_field)\n","\n","\n","    # Determine the join count field name\n","    fields = [f.name for f in arcpy.ListFields(out_path)]\n","    join_count_field = next((f for f in fields if f.lower().startswith(\"join_cou\")), None)\n","\n","    if join_count_field:\n","        arcpy.CalculateField_management(out_path, density_field, f\"!{join_count_field}!\", \"PYTHON3\")\n","        print(f\"Calculated density field: {density_field} from {join_count_field}\")\n","        # Delete the Join_Count field right after\n","        arcpy.DeleteField_management(out_path, join_count_field)\n","        print(f\"Deleted intermediate Join_Count field: {join_count_field}\")\n","\n","    else:\n","        print(\"Warning: Join_Count field not found!\")\n","\n","\n","    # Update current path to new output for next cumulative join\n","    current_streets_path = out_path\n","\n","# After all joins are done\n","all_fields = [f.name for f in arcpy.ListFields(current_streets_path)]\n","\n","# Fields to keep: Shape + fclass + POIS Density Fields\n","keep_fields = ['OBJECTID', 'Shape', 'Shape_Length', 'Shape_Area','fclass'] + pois_density_fields\n","\n","# Determine fields to delete\n","delete_fields = [f for f in all_fields if f not in keep_fields and f.lower() != 'shape']\n","\n","# Delete them in bulk\n","if delete_fields:\n","    arcpy.DeleteField_management(current_streets_path, delete_fields)\n","    print(f\"ðŸ§¹ Final cleanup: Deleted fields â†’ {delete_fields}\")\n","else:\n","    print(\"No extra fields to delete.\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KlOfjKtfzqf_"},"source":["#### Step 3: sDNA analysis\n","(new step) run SDNA analysis with input polyline features from the previous step i.e. with all 4 POIS densities, but weighted by 4 different POIS\n","e.g. 1k x 4 POIS. Unlike the previous step which requires the output to be inside gdb, this step for sDNA toolbox to work the input polyline file has to be outside of a gdb.\n","\"Integral Analysis\" -> check \"betweenness is bidirectional\", radius = 1000; check \"continuous space\", run\n","Destination weight\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBQd3oibzqgA","outputId":"63db438d-ebf7-47c1-d76d-8f1825019298"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running sDNA Integral analysis weighted by p_educivic...\n","Saved sDNA Integral output to D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\\boston_sDNA1k_p_educivic\n","Running sDNA Integral analysis weighted by p_leisure...\n","Saved sDNA Integral output to D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\\boston_sDNA1k_p_leisure\n","Running sDNA Integral analysis weighted by p_shopping...\n","Saved sDNA Integral output to D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\\boston_sDNA1k_p_shopping\n","Running sDNA Integral analysis weighted by p_work...\n","Saved sDNA Integral output to D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\\boston_sDNA1k_p_work\n"]}],"source":["import arcpy\n","import os\n","\n","# Paths\n","input_polyline = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\\boston_st_gd_AllPOIS.shp\"\n","output_folder = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\"\n","\n","# List of your POIS density fields (adjust names exactly as in attribute table)\n","pois_density_fields = ['p_educivic', 'p_leisure', 'p_shopping', 'p_work']  # example names\n","\n","# Import sDNA toolbox with alias 'sdna'\n","sdna_toolbox_path = r\"Z:\\heyutian\\sDNA\\sDNA.pyt\"\n","arcpy.ImportToolbox(sdna_toolbox_path, \"sdna\")\n","\n","# Ensure output folder exists\n","if not arcpy.Exists(output_folder):\n","    arcpy.CreateFolder_management(os.path.dirname(output_folder), os.path.basename(output_folder))\n","\n","# Create a Feature Layer from the input polyline feature class\n","input_layer = \"input_streets_layer\"\n","arcpy.MakeFeatureLayer_management(input_polyline, input_layer)\n","\n","for weight_field in pois_density_fields:\n","    print(f\"Running sDNA Integral analysis weighted by {weight_field}...\")\n","\n","    # Define output path\n","    out_name = f\"boston_sDNA1k_{weight_field}\"\n","    out_path = os.path.join(output_folder, out_name)\n","\n","    # Run the Integral Analysis tool with your parameters\n","    arcpy.sdna.sDNAIntegral(\n","    input=input_layer,\n","    output=out_path,\n","    betweenness=True,\n","    bidir=True,\n","    junctions=False,\n","    hull=False,\n","    start_gs=None,\n","    end_gs=None,\n","    analmet=\"EUCLIDEAN\",\n","    radii=\"1000\",\n","    bandedradii=False,\n","    cont=True,\n","    radmet=\"EUCLIDEAN\",\n","    weighting=\"Link\",\n","    origweight=None,\n","    destweight=weight_field,\n","    zonefiles=None,\n","    odfile=None,\n","    custommetric=None,\n","    disable=\"\",\n","    oneway=None,\n","    intermediates=\"\",\n","    advanced=\"\"\n","    )\n","\n","    print(f\"Saved sDNA Integral output to {out_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"S_UUW_z1zqgA"},"source":["#### Step 4: Spatial joins - NQPD combination then with population\n","Rename the NQPD column to each POI, e.g. nqpd1kwork, before each join, so that they remain discrete. Spatial join the 4 sDNA_POIS_work etc files cumulatively, such that there are 4 columns. Keep default spatial join settings (i.e. intersect, no meters defined).\n","Spatial join network with POP with 30m radius\n","End result will be 5 columns: POP, nqpd1kwork, nqpd1klsr, nqpd1kshop, nqpd1kedcv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KwO52H7QzqgA","outputId":"5090a8aa-6234-4bcd-89e1-a29c9f2a8b30"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copied boston_sDNA1k_p_educivic.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_sDNA1k_p_educivic\n","Copied boston_sDNA1k_p_leisure.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_sDNA1k_p_leisure\n","Copied boston_sDNA1k_p_shopping.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_sDNA1k_p_shopping\n","Copied boston_sDNA1k_p_work.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_sDNA1k_p_work\n","Copied boston_st_gd_AllPOIS.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_st_gd_AllPOIS\n","Renamed field NQPDE1000c to nqpd1keduc in boston_sDNA1k_p_educivic\n","Renamed field NQPDE1000c to nqpd1kleis in boston_sDNA1k_p_leisure\n","Joined boston_sDNA1k_p_leisure into cumulative result â†’ temp_cumulative_1\n","Renamed field NQPDE1000c to nqpd1kshop in boston_sDNA1k_p_shopping\n","Joined boston_sDNA1k_p_shopping into cumulative result â†’ temp_cumulative_2\n","Renamed field NQPDE1000c to nqpd1kwork in boston_sDNA1k_p_work\n","Joined boston_sDNA1k_p_work into cumulative result â†’ temp_cumulative_3\n","Fields in cumulative_fc: ['OBJECTID', 'Shape', 'Join_Count', 'TARGET_FID', 'Join_Count_1', 'TARGET_FID_1', 'Join_Count_12', 'TARGET_FID_12', 'ID', 'p_educivic', 'LConn', 'LLen', 'LFrac', 'LAC', 'LSin', 'LBear', 'MED1000c', 'NQPDE1000c', 'BtFE1000c', 'BtBE1000c', 'TPBtFE1000', 'TPBtBE1000', 'TPD1000c', 'Lnk1000c', 'Len1000c', 'AngD1000c', 'Wt1000c', 'MGLE1000c', 'MCF1000c', 'DivE1000c', 'ID_1', 'p_leisure', 'LConn_1', 'LLen_1', 'LFrac_1', 'LAC_1', 'LSin_1', 'LBear_1', 'MED1000c_1', 'nqpd1kleis', 'BtFE1000c_1', 'BtBE1000c_1', 'TPBtFE1000_1', 'TPBtBE1000_1', 'TPD1000c_1', 'Lnk1000c_1', 'Len1000c_1', 'AngD1000c_1', 'Wt1000c_1', 'MGLE1000c_1', 'MCF1000c_1', 'DivE1000c_1', 'Shape_Length_1', 'ID_12', 'p_shopping', 'LConn_12', 'LLen_12', 'LFrac_12', 'LAC_12', 'LSin_12', 'LBear_12', 'MED1000c_12', 'nqpd1kshop', 'BtFE1000c_12', 'BtBE1000c_12', 'TPBtFE1000_12', 'TPBtBE1000_12', 'TPD1000c_12', 'Lnk1000c_12', 'Len1000c_12', 'AngD1000c_12', 'Wt1000c_12', 'MGLE1000c_12', 'MCF1000c_12', 'DivE1000c_12', 'Shape_Length_12', 'ID_12_13', 'p_work', 'LConn_12_13', 'LLen_12_13', 'LFrac_12_13', 'LAC_12_13', 'LSin_12_13', 'LBear_12_13', 'MED1000c_12_13', 'nqpd1kwork', 'BtFE1000c_12_13', 'BtBE1000c_12_13', 'TPBtFE1000_12_13', 'TPBtBE1000_12_13', 'TPD1000c_12_13', 'Lnk1000c_12_13', 'Len1000c_12_13', 'AngD1000c_12_13', 'Wt1000c_12_13', 'MGLE1000c_12_13', 'MCF1000c_12_13', 'DivE1000c_12_13', 'Shape_Length_12_13', 'Shape_Length']\n","WARNING: Field 'nqpd1keduc' not found in cumulative_fc!\n"]},{"ename":"RuntimeError","evalue":"FieldMap: Error in adding input field to field map","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","In  \u001b[0;34m[13]\u001b[0m:\nLine \u001b[0;34m86\u001b[0m:    fmap.addInputField(cumulative_fc, field_name)\u001b[37m\u001b[39;49;00m\n","File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\arcobjects\\arcobjects.py\u001b[0m, in \u001b[0;32maddInputField\u001b[0m:\nLine \u001b[0;34m683\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m convertArcObjectToPythonObject(\u001b[36mself\u001b[39;49;00m._arc_object.AddInputField(*gp_fixargs(args)))\u001b[37m\u001b[39;49;00m\n","\u001b[0;31mRuntimeError\u001b[0m: FieldMap: Error in adding input field to field map\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}],"source":["# import arcpy\n","# import os\n","\n","# # Paths\n","# input_shp_folder = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\"\n","# gdb_path = r\"Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\"\n","\n","# # Step 1: Copy shapefiles to GDB as feature classes\n","# shp_files = [f for f in os.listdir(input_shp_folder) if f.endswith(\".shp\")]\n","\n","# for shp in shp_files:\n","#     shp_path = os.path.join(input_shp_folder, shp)\n","#     out_name = os.path.splitext(shp)[0]\n","#     out_fc = os.path.join(gdb_path, out_name)\n","\n","#     # Copy shapefile to gdb as feature class\n","#     arcpy.FeatureClassToFeatureClass_conversion(shp_path, gdb_path, out_name)\n","#     print(f\"Copied {shp} to {out_fc}\")\n","\n","# # Step 2: Set arcpy workspace to gdb for easy listing of feature classes\n","# arcpy.env.workspace = gdb_path\n","\n","# # List feature classes in GDB starting with sDNA prefix\n","# sdna_fcs = arcpy.ListFeatureClasses(\"boston_sDNA1k_p_*\")\n","\n","# # Use first file as base for cumulative join\n","# base_fc = sdna_fcs[0]\n","# cumulative_fc = \"temp_cumulative\"\n","# arcpy.CopyFeatures_management(base_fc, cumulative_fc)\n","\n","# # Process each sDNA feature class\n","# for i, sdna_fc in enumerate(sdna_fcs):\n","#     suffix = sdna_fc.split(\"boston_sDNA1k_p_\")[-1][:4]\n","#     nqpd_field_new = f\"nqpd1k{suffix}\"\n","\n","#     # Rename NQPD field inside the feature class\n","#     fields = arcpy.ListFields(sdna_fc)\n","#     nqpd_field = next((f.name for f in fields if f.name.upper().startswith(\"NQPD\")), None)\n","\n","#     if nqpd_field:\n","#         arcpy.AlterField_management(sdna_fc, nqpd_field, new_field_name=nqpd_field_new)\n","#         print(f\"Renamed field {nqpd_field} to {nqpd_field_new} in {sdna_fc}\")\n","#     else:\n","#         print(f\"NQPD field not found in {sdna_fc}\")\n","\n","#     # Skip cumulative join for base file (already copied)\n","#     if i == 0:\n","#         continue\n","\n","#     # Cumulative spatial join - output a new FC each time\n","#     out_temp = f\"temp_cumulative_{i}\"\n","#     arcpy.analysis.SpatialJoin(\n","#         target_features=cumulative_fc,\n","#         join_features=sdna_fc,\n","#         out_feature_class=out_temp,\n","#         join_operation=\"JOIN_ONE_TO_ONE\",\n","#         join_type=\"KEEP_ALL\",\n","#         match_option=\"INTERSECT\"\n","#     )\n","#     print(f\"Joined {sdna_fc} into cumulative result â†’ {out_temp}\")\n","#     cumulative_fc = out_temp\n","\n","# # Final Spatial Join with POP â€” FieldMappings Setup\n","# pop_layer = r\"D:\\UserData16\\heyutian\\data\\00_Clean\\Boston_data\\boston_pop_blocks.shp\"\n","# output_final = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_2_nqpd1k_boston_st_gd\\boston_nqpf1k_allPOIS_stgd.shp\"\n","\n","# # Build FieldMappings cleanly\n","# field_mappings = arcpy.FieldMappings()\n","\n","# fields_in_cumulative = [f.name for f in arcpy.ListFields(cumulative_fc)]\n","# print(\"Fields in cumulative_fc:\", fields_in_cumulative)\n","\n","# for field_name in ['nqpd1kwork', 'nqpd1kleis', 'nqpd1kshop', 'nqpd1keduc']:\n","#     if field_name not in fields_in_cumulative:\n","#         print(f\"WARNING: Field '{field_name}' not found in cumulative_fc!\")\n","#     else:\n","#         fmap = arcpy.FieldMap()\n","#         fmap.addInputField(cumulative_fc, field_name)\n","#         fmap.outputField.name = field_name\n","#         fmap.outputField.aliasName = field_name\n","#         field_mappings.addFieldMap(fmap)\n","\n","# # Add all NQPD fields (they now exist in cumulative_fc)\n","# for field_name in ['nqpd1kwork', 'nqpd1kleis', 'nqpd1kshop', 'nqpd1keduc']:\n","#     fmap = arcpy.FieldMap()\n","#     fmap.addInputField(cumulative_fc, field_name)\n","#     fmap.outputField.name = field_name\n","#     fmap.outputField.aliasName = field_name\n","#     field_mappings.addFieldMap(fmap)\n","\n","# # Add POP20 from pop_layer\n","# fmap_pop = arcpy.FieldMap()\n","# fmap_pop.addInputField(pop_layer, 'POP20')\n","# fmap_pop.outputField.name = 'POP20'\n","# fmap_pop.outputField.aliasName = 'POP20'\n","# field_mappings.addFieldMap(fmap_pop)\n","\n","# # Perform Spatial Join with POP20, keeping only desired fields\n","# arcpy.SpatialJoin_analysis(\n","#     target_features=cumulative_fc,\n","#     join_features=pop_layer,\n","#     out_feature_class=output_final,\n","#     join_operation=\"JOIN_ONE_TO_ONE\",\n","#     join_type=\"KEEP_ALL\",\n","#     match_option=\"WITHIN_A_DISTANCE\",\n","#     search_radius=\"30 Meters\",\n","#     field_mapping=field_mappings\n","# )\n","# print(f\"Final network with POP joined â†’ {output_final}\")\n","\n","# # Cleanup: Delete all intermediate temp_cumulative_* feature classes\n","# arcpy.env.workspace = gdb_path\n","# temp_fcs = arcpy.ListFeatureClasses(\"temp_cumulative*\")\n","\n","# for temp_fc in temp_fcs:\n","#     arcpy.Delete_management(temp_fc)\n","#     print(f\"Deleted intermediate feature class: {temp_fc}\")\n","\n","# print(\"Cleanup complete!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BzxyYXnzqgA","outputId":"a538456f-e826-498f-b81c-7f406a20dc57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copied boston_sDNA1k_p_educivic.shp to boston_sDNA1k_p_educivic\n","Copied boston_sDNA1k_p_leisure.shp to boston_sDNA1k_p_leisure\n","Copied boston_sDNA1k_p_shopping.shp to boston_sDNA1k_p_shopping\n","Copied boston_sDNA1k_p_work.shp to boston_sDNA1k_p_work\n","Copied boston_st_gd_AllPOIS.shp to boston_st_gd_AllPOIS\n","Renamed field NQPDE1000c to nqpd1keduc in boston_sDNA1k_p_educivic\n","Renamed field NQPDE1000c to nqpd1kleis in boston_sDNA1k_p_leisure\n","Renamed field NQPDE1000c to nqpd1kshop in boston_sDNA1k_p_shopping\n","Renamed field NQPDE1000c to nqpd1kwork in boston_sDNA1k_p_work\n","Joined boston_sDNA1k_p_educivic â†’ boston_sDNA1k_p_educivic_joined\n","Joined boston_sDNA1k_p_leisure â†’ boston_sDNA1k_p_leisure_joined\n","Joined boston_sDNA1k_p_shopping â†’ boston_sDNA1k_p_shopping_joined\n","Joined boston_sDNA1k_p_work â†’ boston_sDNA1k_p_work_joined\n","Joined field nqpd1keduc from boston_sDNA1k_p_educivic_joined into network_base\n","Joined field nqpd1kleis from boston_sDNA1k_p_leisure_joined into network_base\n","Joined field nqpd1kshop from boston_sDNA1k_p_shopping_joined into network_base\n","Joined field nqpd1kwork from boston_sDNA1k_p_work_joined into network_base\n","Final spatial join with POP done: D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_2_nqpd1k_boston_st_gd\\boston_nqpf1k_allPOIS_stgd.shp\n"]}],"source":["# import arcpy\n","# import os\n","\n","# # Paths\n","# input_shp_folder = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\"\n","# gdb_path = r\"Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\"\n","# pop_layer = r\"D:\\UserData16\\heyutian\\data\\00_Clean\\Boston_data\\boston_pop_blocks.shp\"\n","# output_final = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_2_nqpd1k_boston_st_gd\\boston_nqpf1k_allPOIS_stgd.shp\"\n","\n","# # Step 1: Copy shapefiles to GDB as feature classes\n","# shp_files = [f for f in os.listdir(input_shp_folder) if f.endswith(\".shp\")]\n","\n","# for shp in shp_files:\n","#     shp_path = os.path.join(input_shp_folder, shp)\n","#     out_name = os.path.splitext(shp)[0]\n","#     arcpy.FeatureClassToFeatureClass_conversion(shp_path, gdb_path, out_name)\n","#     print(f\"Copied {shp} to {out_name}\")\n","\n","# arcpy.env.workspace = gdb_path\n","\n","# # Step 2: Rename NQPD fields uniquely in each POI feature class\n","# sdna_fcs = arcpy.ListFeatureClasses(\"boston_sDNA1k_p_*\")\n","# renamed_fcs = []\n","\n","# for fc in sdna_fcs:\n","#     suffix = fc.split(\"boston_sDNA1k_p_\")[-1][:4]\n","#     new_field_name = f\"nqpd1k{suffix}\"\n","\n","#     fields = arcpy.ListFields(fc)\n","#     nqpd_field = next((f.name for f in fields if f.name.upper().startswith(\"NQPD\")), None)\n","#     if nqpd_field:\n","#         arcpy.AlterField_management(fc, nqpd_field, new_field_name=new_field_name)\n","#         print(f\"Renamed field {nqpd_field} to {new_field_name} in {fc}\")\n","#         renamed_fcs.append((fc, new_field_name))\n","#     else:\n","#         print(f\"No NQPD field found in {fc}\")\n","\n","# # Step 3: Copy base network for join target\n","# base_fc = sdna_fcs[0]  # or your preferred network FC\n","# network_fc = \"network_base\"\n","# arcpy.CopyFeatures_management(base_fc, network_fc)\n","\n","# # Step 4: For each POI FC, spatial join to network, output separate join FCs\n","# joined_fcs = []\n","\n","# for fc, nqpd_field in renamed_fcs:\n","#     out_join_fc = f\"{fc}_joined\"\n","#     arcpy.analysis.SpatialJoin(\n","#         target_features=network_fc,\n","#         join_features=fc,\n","#         out_feature_class=out_join_fc,\n","#         join_operation=\"JOIN_ONE_TO_ONE\",\n","#         join_type=\"KEEP_ALL\",\n","#         match_option=\"INTERSECT\"\n","#     )\n","#     print(f\"Joined {fc} â†’ {out_join_fc}\")\n","#     joined_fcs.append((out_join_fc, nqpd_field))\n","\n","# # Step 5: Iteratively join each POI join FC back to network by unique ID (assumes 'OBJECTID' or similar unique key)\n","# # We'll do attribute joins here to add each NQPD field to network_fc\n","\n","# # Use a unique ID field present in all feature classes\n","# unique_id_field = \"OBJECTID\"  # Change if your ID field differs\n","\n","# for join_fc, nqpd_field in joined_fcs:\n","#     temp_joined = \"network_with_\" + nqpd_field\n","#     arcpy.JoinField_management(\n","#         in_data=network_fc,\n","#         in_field=unique_id_field,\n","#         join_table=join_fc,\n","#         join_field=unique_id_field,\n","#         fields=[nqpd_field]\n","#     )\n","#     print(f\"Joined field {nqpd_field} from {join_fc} into {network_fc}\")\n","\n","# # Step 6: Spatial join POP data with field mapping for just POP20 and existing fields\n","# field_mappings = arcpy.FieldMappings()\n","\n","# # Add all fields from network_fc except shape (you can customize this list)\n","# for field in arcpy.ListFields(network_fc):\n","#     if field.type != 'Geometry':\n","#         fmap = arcpy.FieldMap()\n","#         fmap.addInputField(network_fc, field.name)\n","#         fmap.outputField.name = field.name\n","#         fmap.outputField.aliasName = field.aliasName\n","#         field_mappings.addFieldMap(fmap)\n","\n","# # Add POP20 field from pop_layer\n","# fmap_pop = arcpy.FieldMap()\n","# fmap_pop.addInputField(pop_layer, 'POP20')\n","# fmap_pop.outputField.name = 'POP20'\n","# fmap_pop.outputField.aliasName = 'POP20'\n","# field_mappings.addFieldMap(fmap_pop)\n","\n","# # Perform spatial join with POP\n","# arcpy.analysis.SpatialJoin(\n","#     target_features=network_fc,\n","#     join_features=pop_layer,\n","#     out_feature_class=output_final,\n","#     join_operation=\"JOIN_ONE_TO_ONE\",\n","#     join_type=\"KEEP_ALL\",\n","#     match_option=\"WITHIN_A_DISTANCE\",\n","#     search_radius=\"30 Meters\",\n","#     field_mapping=field_mappings\n","# )\n","# print(f\"Final spatial join with POP done: {output_final}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"WXGk8MvCzqgA","outputId":"70790436-466f-4ab7-fe29-b3ed2482b46b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copied boston_sDNA1k_p_educivic.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_sDNA1k_p_educivic\n","Copied boston_sDNA1k_p_leisure.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_sDNA1k_p_leisure\n","Copied boston_sDNA1k_p_shopping.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_sDNA1k_p_shopping\n","Copied boston_sDNA1k_p_work.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_sDNA1k_p_work\n","Copied boston_st_gd_AllPOIS.shp to Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\\boston_st_gd_AllPOIS\n","Added new field nqpd1keduc in boston_sDNA1k_p_educivic\n","Copied data from NQPDE1000c to nqpd1keduc in boston_sDNA1k_p_educivic\n","Added new field nqpd1kleis in boston_sDNA1k_p_leisure\n","Copied data from NQPDE1000c to nqpd1kleis in boston_sDNA1k_p_leisure\n","Added new field nqpd1kshop in boston_sDNA1k_p_shopping\n","Copied data from NQPDE1000c to nqpd1kshop in boston_sDNA1k_p_shopping\n","Added new field nqpd1kwork in boston_sDNA1k_p_work\n","Copied data from NQPDE1000c to nqpd1kwork in boston_sDNA1k_p_work\n"]},{"ename":"RuntimeError","evalue":"Object: Error in executing tool","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","In  \u001b[0;34m[21]\u001b[0m:\nLine \u001b[0;34m68\u001b[0m:    arcpy.analysis.SpatialJoin(\u001b[37m\u001b[39;49;00m\n","File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py\u001b[0m, in \u001b[0;32mSpatialJoin\u001b[0m:\nLine \u001b[0;34m749\u001b[0m:   \u001b[34mraise\u001b[39;49;00m e\u001b[37m\u001b[39;49;00m\n","File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py\u001b[0m, in \u001b[0;32mSpatialJoin\u001b[0m:\nLine \u001b[0;34m746\u001b[0m:   retval = convertArcObjectToPythonObject(gp.SpatialJoin_analysis(*gp_fixargs((target_features, join_features, out_feature_class, join_operation, join_type, field_mapping, match_option, search_radius, distance_field_name, match_fields), \u001b[34mTrue\u001b[39;49;00m)))\u001b[37m\u001b[39;49;00m\n","File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n","\u001b[0;31mRuntimeError\u001b[0m: Object: Error in executing tool\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}],"source":["import arcpy\n","import os\n","\n","# Paths\n","input_shp_folder = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_sDNA_POIS_Boston_st_gd\"\n","gdb_path = r\"Z:\\heyutian\\Kaunas_Boston\\Boston\\Boston.gdb\"\n","pop_layer = r\"D:\\UserData16\\heyutian\\data\\00_Clean\\Boston_data\\boston_pop_blocks.shp\"\n","output_final = r\"D:\\UserData16\\heyutian\\data\\01_Reference\\20250804_2_nqpd1k_boston_st_gd\\boston_nqpf1k_allPOIS_stgd.shp\"\n","\n","# Step 1: Copy shapefiles to GDB as feature classes\n","shp_files = [f for f in os.listdir(input_shp_folder) if f.endswith(\".shp\")]\n","for shp in shp_files:\n","    shp_path = os.path.join(input_shp_folder, shp)\n","    out_name = os.path.splitext(shp)[0]\n","    out_fc = os.path.join(gdb_path, out_name)\n","    arcpy.FeatureClassToFeatureClass_conversion(shp_path, gdb_path, out_name)\n","    print(f\"Copied {shp} to {out_fc}\")\n","\n","# Step 2: Set arcpy workspace to gdb\n","arcpy.env.workspace = gdb_path\n","\n","# Identify base network geometry (e.g., streets)\n","base_fc = \"boston_st_gd_AllPOIS\"  # Assuming this is the network base layer\n","\n","# List sDNA feature classes (assuming naming boston_sDNA1k_p_*)\n","sdna_fcs = arcpy.ListFeatureClasses(\"boston_sDNA1k_p_*\")\n","\n","# Step 3: For each sDNA fc, create new NQPD field by copying from original\n","for sdna_fc in sdna_fcs:\n","    suffix = sdna_fc.split(\"boston_sDNA1k_p_\")[-1][:4]\n","    new_nqpd_field = f\"nqpd1k{suffix}\"\n","\n","    fields = arcpy.ListFields(sdna_fc)\n","    orig_nqpd_field = next((f.name for f in fields if f.name.upper().startswith(\"NQPD\")), None)\n","\n","    if orig_nqpd_field is None:\n","        print(f\"Original NQPD field not found in {sdna_fc}. Skipping field creation.\")\n","    else:\n","        if new_nqpd_field not in [f.name for f in fields]:\n","            arcpy.AddField_management(sdna_fc, new_nqpd_field, \"DOUBLE\")\n","            print(f\"Added new field {new_nqpd_field} in {sdna_fc}\")\n","        arcpy.CalculateField_management(sdna_fc, new_nqpd_field, f\"!{orig_nqpd_field}!\", \"PYTHON3\")\n","        print(f\"Copied data from {orig_nqpd_field} to {new_nqpd_field} in {sdna_fc}\")\n","\n","# Step 4: Build FieldMappings combining all sDNA NQPD fields\n","field_mappings = arcpy.FieldMappings()\n","\n","# Add all fields from base_fc (geometry & IDs)\n","base_fields = arcpy.ListFields(base_fc)\n","for field in base_fields:\n","    if field.type not in [\"Geometry\"]:\n","        fmap = arcpy.FieldMap()\n","        fmap.addInputField(base_fc, field.name)\n","        field_mappings.addFieldMap(fmap)\n","\n","# Add the new NQPD fields from each sDNA layer\n","for sdna_fc in sdna_fcs:\n","    suffix = sdna_fc.split(\"boston_sDNA1k_p_\")[-1][:4]\n","    nqpd_field = f\"nqpd1k{suffix}\"\n","    fmap = arcpy.FieldMap()\n","    fmap.addInputField(sdna_fc, nqpd_field)\n","    fmap.outputField.name = nqpd_field\n","    fmap.outputField.aliasName = nqpd_field\n","    field_mappings.addFieldMap(fmap)\n","\n","# Perform spatial join of all sDNA layers into base network geometry\n","combined_sDNA_output = \"network_with_nqpd\"\n","arcpy.analysis.SpatialJoin(\n","    target_features=base_fc,\n","    join_features=sdna_fcs,\n","    out_feature_class=combined_sDNA_output,\n","    join_operation=\"JOIN_ONE_TO_ONE\",\n","    join_type=\"KEEP_ALL\",\n","    match_option=\"INTERSECT\",\n","    field_mapping=field_mappings\n",")\n","print(f\"Combined sDNA layers into {combined_sDNA_output}\")\n","\n","# Step 5: Spatial Join with POP (Final Join)\n","final_field_mappings = arcpy.FieldMappings()\n","\n","# Keep all existing fields from combined_sDNA_output\n","for field in arcpy.ListFields(combined_sDNA_output):\n","    if field.type not in [\"Geometry\"]:\n","        fmap = arcpy.FieldMap()\n","        fmap.addInputField(combined_sDNA_output, field.name)\n","        final_field_mappings.addFieldMap(fmap)\n","\n","# Add POP20 field from pop_layer\n","fmap_pop = arcpy.FieldMap()\n","fmap_pop.addInputField(pop_layer, 'POP20')\n","fmap_pop.outputField.name = 'POP20'\n","fmap_pop.outputField.aliasName = 'POP20'\n","final_field_mappings.addFieldMap(fmap_pop)\n","\n","# Execute final spatial join\n","arcpy.analysis.SpatialJoin(\n","    target_features=combined_sDNA_output,\n","    join_features=pop_layer,\n","    out_feature_class=output_final,\n","    join_operation=\"JOIN_ONE_TO_ONE\",\n","    join_type=\"KEEP_ALL\",\n","    match_option=\"WITHIN_A_DISTANCE\",\n","    search_radius=\"30 Meters\",\n","    field_mapping=final_field_mappings\n",")\n","print(f\"Final network with POP joined â†’ {output_final}\")\n","\n","print(\"All done!\")\n"]},{"cell_type":"markdown","metadata":{"id":"yFBfYpfvzqgB"},"source":["#### Step 5: Export as txt file(s) for IBM SPSS correlation calculations"]}],"metadata":{"kernelspec":{"display_name":"ArcGISPro","language":"Python","name":"python3"},"language_info":{"file_extension":".py","name":"python","version":"3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}